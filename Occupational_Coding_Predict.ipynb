{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupational Coding Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Read data and output\n",
    "\n",
    "import jieba # Word segmentation\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "import numpy as np # Data processing\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool1D, Conv1D, Convolution1D\n",
    "from keras.layers import Embedding\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "from gensim.models import KeyedVectors # Import pre-trained word vectos\n",
    "\n",
    "import matplotlib.pyplot as plt # Draw graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "Set up for training the model<br>\n",
    "Variables needed to be set: word2vec_path, stopwords_path, vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file paths needed and dimension of the pre-trained word vectors\n",
    "\n",
    "stopwords_path = 'stopword.txt' # Stop-words file\n",
    "word2vec_path = 'tencent-ailab-embedding-zh-d200-v0.2.0-s.txt' # Pre-trained word vectors file\n",
    "\n",
    "vec_size = 200 # Deimension of the pre-trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained word vectors\n",
    "\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(word2vec_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare functions used\n",
    "\n",
    "# Create list of stop-words\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    " \n",
    " \n",
    "# Word segmentation\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = jieba.lcut(sentence.strip())\n",
    "    stopwords = stopwordslist(stopwords_path)\n",
    "    outstr = []\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords: # Delete the stop-words\n",
    "            if word != '\\t' and word != ' ': # Delete spaces\n",
    "                outstr.append(word)\n",
    "    return outstr\n",
    "\n",
    "# Change the words segemented into word vectors\n",
    "def transform_to_matrix(x, padding_size=10, vec_size=vec_size):\n",
    "    res = []\n",
    "    for sen in x:\n",
    "        matrix = []\n",
    "        for i in range(padding_size):\n",
    "            try:\n",
    "                matrix.append(wv_from_text[sen[i]].tolist())\n",
    "            except:\n",
    "                matrix.append([0] * vec_size)\n",
    "        res.append(matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Prediction\n",
    "Variables needed to be set: predict_path, output_path, predict_name, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "\n",
    "predict_path = 'zy_predict.xlsx' # Data to be predicted\n",
    "output_path = 'output_zy.xlsx' # Output the prediction result\n",
    "model_path = 'model_zy.h5' # Path of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data to be predicted\n",
    "predict_pd = pd.read_excel(predict_path, index_col=0)\n",
    "\n",
    "# Set column name of the data to be predicted\n",
    "predict_name = 'QG303'\n",
    "\n",
    "# Data processing\n",
    "x = predict_pd[predict_name]\n",
    "x = np.array(x)\n",
    "temp = []\n",
    "for i in x:\n",
    "    line_seg = seg_sentence(i)\n",
    "    temp.append(line_seg)\n",
    "x = temp\n",
    "\n",
    "x = transform_to_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict function to predict coding of the data\n",
    "# Convert possibilities into exact codes\n",
    "# Export prediction result to excel file\n",
    "\n",
    "predict = model.predict(x)\n",
    "predict_1 = predict.argmax(axis=-1)\n",
    "predict_1 = np.array(predict_1)\n",
    "te = pd.DataFrame(predict_1)\n",
    "te.to_excel(output_path, sheet_name='Sheet1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7994908c881ac51252aa6b158559f16fb3043709f3a2bdd1c7e20729cc39315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
